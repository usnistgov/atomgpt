coverage run -m pytest atomgpt/tests/test_inverse.py

=================================================================== 5 warnings in 48.92s ====================================================================
(/lab/mml/kipp/677/jarvis/Software/atomgpt_no_us) knc6@rw02:/lab/mml/kipp/677/jarvis/Software/atomgpt_hf/atomgpt$ coverage report -m -i
/lab/mml/kipp/677/jarvis/Software/atomgpt_no_us/lib/python3.10/site-packages/coverage/report_core.py:116: CoverageWarning: Couldn't parse '/tmp/tmpyx7arp2h/_remote_module_non_scriptable.py': No source for code: '/tmp/tmpyx7arp2h/_remote_module_non_scriptable.py'. (couldnt-parse)
  coverage._warn(msg, slug="couldnt-parse")
Name                                                        Stmts   Miss  Cover   Missing
-----------------------------------------------------------------------------------------
atomgpt/__init__.py                                             1      0   100%
atomgpt/inverse_models/__init__.py                              0      0   100%
atomgpt/inverse_models/_utils2.py                              47     17    64%   25-29, 40-41, 50, 58-69, 92-93
atomgpt/inverse_models/_utils.py                              676    282    58%   113, 160-164, 175-176, 185, 192-207, 254-255, 267-268, 280-281, 291-292, 300-301, 311-337, 355-373, 400-401, 405-406, 420, 433-434, 468-478, 496-539, 544, 573, 580, 587, 597-598, 609-612, 672, 692-696, 720-721, 738-768, 801-831, 850, 852, 854, 856, 858, 860, 863, 882, 884, 886, 892-893, 902-903, 919, 941, 943, 945, 947, 949, 951, 953, 957-958, 963-964, 1008, 1047-1067, 1076-1087, 1096-1113, 1128, 1156-1158, 1201-1204, 1219-1308, 1316-1324, 1331-1370, 1377-1412, 1431, 1449, 1459, 1464, 1537-1539, 1579-1585, 1588-1592, 1595, 1630, 1649, 1653, 1661, 1667, 1670, 1693-1697
atomgpt/inverse_models/callbacks.py                            90     74    18%   29-36, 47-48, 57-58, 61-106, 112-116, 132-138, 147-148, 157-158, 163-227
atomgpt/inverse_models/cohere.py                              274    243    11%   14-25, 45-52, 77-178, 199-259, 280-454, 469-521, 536-562
atomgpt/inverse_models/compiler.py                            964    243    75%   57, 69, 197, 207, 266-274, 279-290, 327, 345, 370-371, 374-375, 405, 414, 432-444, 458, 468-507, 514, 545, 563, 575, 589-593, 608, 1184, 1197-1198, 1223-1224, 1246-1297, 1317, 1367-1368, 1373-1416, 1486, 1537-1538, 1579-1619, 1651-1695, 1739, 1763-1764, 1767-1768, 1882-1883, 1908-1912, 1940-1941, 1976-1977, 1999-2015, 2032-2033, 2037-2039, 2052, 2056-2057, 2086-2089, 2094-2097, 2110-2125, 2145-2146, 2173-2174, 2189-2190, 2208-2223, 2241, 2249-2250, 2279-2291, 2306-2307, 2319-2322, 2325-2326, 2464-2465, 2471, 2484-2488, 2513-2516, 2529-2530, 2532, 2534, 2537, 2539, 2565-2566, 2579-2580, 2586
atomgpt/inverse_models/compiler_replacements.py                 3      0   100%
atomgpt/inverse_models/dataset_utils.py                       383    366     4%   14-27, 44-97, 111-179, 199-448, 481-572, 601-755
atomgpt/inverse_models/gemma2.py                              284    246    13%   19-30, 49, 56-63, 87-168, 188-265, 288-452, 467-549, 564-595, 602-640
atomgpt/inverse_models/gemma.py                               190    143    25%   15-26, 51-62, 82-146, 164-222, 247-269, 280-304, 310-315, 323, 328-332, 357-358, 371-396, 408-439, 446-484
atomgpt/inverse_models/gradient_checkpointing.py              386    280    27%   26-27, 38-58, 68-80, 105-126, 142-149, 156-164, 186-191, 198-204, 225, 232-249, 256-269, 276-283, 290-297, 327-334, 422-562, 569-699, 838-881, 909-930, 941-943
atomgpt/inverse_models/granite.py                             303    262    14%   19-30, 67-182, 202-274, 299-439, 454-521, 534, 538-548, 555-583, 592-667
atomgpt/inverse_models/inverse_models.py                      279    207    26%   105-135, 148-175, 179-188, 194-206, 212-243, 255-327, 331-634, 640-641
atomgpt/inverse_models/kernels/__init__.py                      9      0   100%
atomgpt/inverse_models/kernels/cross_entropy_loss.py          157    122    22%   53-89, 140-181, 223-274, 301-379, 385-417, 444-455, 462
atomgpt/inverse_models/kernels/fast_lora.py                   181    132    27%   76-97, 104-196, 231-259, 272-300, 313-340, 399-426, 433-524, 551-573, 610-618, 625-657, 666-668, 679
atomgpt/inverse_models/kernels/flex_attention.py              111     89    20%   25-26, 35-69, 79-158, 170-202
atomgpt/inverse_models/kernels/geglu.py                       113     89    21%   19-33, 40-53, 77-108, 115-126, 140-161, 168-181, 209-243, 250-261
atomgpt/inverse_models/kernels/layernorm.py                   120     95    21%   27-50, 71-97, 106-135, 141-163, 172-181, 195-215, 222-239
atomgpt/inverse_models/kernels/rms_layernorm.py               172    127    26%   29-46, 74-102, 131-148, 159-194, 200-230, 241-248, 259, 271, 276-277, 282-295, 302-313, 327-346, 353-370
atomgpt/inverse_models/kernels/rope_embedding.py               99     69    30%   30-79, 94-143, 153-184, 199-201, 210-225, 231-239, 248-250
atomgpt/inverse_models/kernels/swiglu.py                       53     39    26%   18-32, 39-51, 74-101, 108-119
atomgpt/inverse_models/kernels/utils.py                       332    261    21%   14-15, 33-40, 48-61, 75, 80, 89, 137, 142-157, 171-193, 211-315, 320-395, 402-507, 512-612, 618-659, 666-688
atomgpt/inverse_models/llama.py                              1460   1056    28%   31, 69-71, 82-85, 92-93, 112-123, 182-355, 367-378, 388-405, 412-425, 434-445, 470-592, 628-683, 717-1117, 1142-1229, 1263-1435, 1466, 1512, 1567-1572, 1580, 1585-1591, 1616-1617, 1628-1651, 1674-1708, 1719-1735, 1746-1768, 1774-1779, 1787, 1792-1798, 1821-1907, 1914-1931, 1937-1948, 1957-1959, 1964-1970, 1985-2047, 2057-2093, 2120-2124, 2130-2140, 2144, 2146, 2171, 2173, 2177, 2182, 2189-2193, 2218-2219, 2224, 2229-2257, 2296-2334, 2377-2378, 2579-3102, 3112, 3118, 3127, 3130-3145, 3180, 3193-3196, 3272, 3306-3313, 3330, 3377-3385, 3401-3435, 3441-3482
atomgpt/inverse_models/loader.py                              359    107    70%   24-30, 97, 130-135, 143-145, 168-170, 193-199, 211, 218, 226-241, 263-284, 289-296, 298-320, 322, 325, 375, 381-404, 431, 443, 507-508, 548, 550, 554-558, 565-569, 573, 591, 599, 607, 615, 620-623, 629, 636-643, 648, 652-654, 677-679, 702-708, 719, 726, 734-749, 771, 796-798, 851, 890, 902
atomgpt/inverse_models/loader_utils.py                         53     15    72%   35-43, 47-52, 56-57, 67-75, 106-107, 129, 150
atomgpt/inverse_models/logging_utils.py                       144    116    19%   26, 38-55, 62-81, 88-139, 146-165, 175-239, 247-254
atomgpt/inverse_models/loss_utils.py                          164    102    38%   18, 23, 37-40, 57-61, 72-88, 101-114, 119, 122-130, 151, 199-215, 234-258, 271-354
atomgpt/inverse_models/mapper.py                               29      0   100%
atomgpt/inverse_models/mistral.py                             194    153    21%   46-167, 192-344, 358-370, 388-391
atomgpt/inverse_models/patch_torch_functions.py                28      8    71%   41-51, 140-155
atomgpt/inverse_models/patching_utils.py                      357    115    68%   33-34, 59-75, 88-103, 117-118, 196-197, 221, 223, 225, 231, 233, 235, 242-243, 248-249, 258-259, 263-280, 322, 342-343, 349-352, 365-366, 371-372, 382-404, 462, 491-492, 494, 498-521, 538-577, 666, 691-696, 700-706, 710
atomgpt/inverse_models/peft_utils.py                          186    155    17%   70-174, 221-402
atomgpt/inverse_models/qwen2.py                                34     17    50%   29-60, 79
atomgpt/inverse_models/qwen3.py                               228    186    18%   18-29, 64-200, 244-427, 444-445
atomgpt/inverse_models/qwen3_moe.py                            80     61    24%   41-80, 101-165, 172-207, 226
atomgpt/inverse_models/rl.py                                  324     39    88%   35-39, 52-78, 90-91, 95-96, 173-174, 192, 201-202, 205-206, 210, 212, 268-269, 552, 561, 758, 856
atomgpt/inverse_models/rl_replacements.py                     279    146    48%   56-66, 78-115, 148-285, 295-296, 324-387, 431, 464-511, 527-533, 551, 581, 599-630, 659-728, 744, 746, 765
atomgpt/inverse_models/save.py                                858    744    13%   82-84, 93-107, 114-134, 142-172, 180-188, 221-854, 861-870, 880-891, 898-902, 911-974, 985-1010, 1018-1062, 1082-1321, 1354-1366, 1399-1414, 1446-1464, 1480-1545, 1602-1696, 1746-1840, 1873-1888, 1921-1933, 1947-1983, 2126-2240
atomgpt/inverse_models/tokenizer_utils.py                     834    664    20%   54-85, 103-229, 244-538, 580-583, 588-679, 737-785, 792-799, 813-887, 947, 1028-1038, 1053-1109, 1121-1191, 1207, 1211, 1232-1233, 1241, 1253, 1259, 1264, 1268, 1274-1280, 1322, 1327, 1341-1348, 1356-1387, 1400-1474, 1497, 1510-1644, 1687-1693, 1703-1874
atomgpt/inverse_models/training_utils.py                      272    186    32%   30-75, 109-110, 114-119, 135-148, 165-167, 179, 187, 199-202, 216-238, 246-250, 258-262, 287-525
atomgpt/inverse_models/utils.py                               347    308    11%   23-31, 37-38, 44-56, 62-73, 78-91, 96-109, 120-176, 188-241, 246-275, 279-308, 318-335, 347-371, 375-394, 398-420, 424-447, 458-491, 495-503, 518-549, 586-687, 693-734, 745-792, 796-812
atomgpt/inverse_models/vision.py                              457    251    45%   13-14, 49-51, 83-239, 268, 274, 280, 311, 313-315, 317, 322, 327, 329-330, 332-335, 342-346, 353-358, 365-368, 373-377, 381, 392-398, 404-410, 424, 441-442, 457, 578-662, 682, 702, 744-778, 784-825
atomgpt/inverse_models/vision_utils.py                        252    204    19%   51, 59, 67, 89-103, 113-159, 168-182, 194-209, 218-234, 241-255, 299-410, 417-529
atomgpt/inverse_models/vllm_utils.py                         1128   1014    10%   44, 47, 54, 58, 62, 68-349, 353, 358, 363, 368, 373, 378, 403-469, 478-484, 492-493, 499-503, 508-509, 514-527, 534-544, 559-586, 597-768, 779-813, 823-843, 855-1056, 1074-1163, 1199-1525, 1534-1541, 1550-1559, 1567-1569, 1578-1584, 1593-1705, 1714-1730, 1744-1765, 1777-1793, 1814-1866, 1877-1913, 1921-1943, 1951-2107, 2124-2295, 2303-2375
atomgpt/tests/test_inverse.py                                  12      0   100%
atomgpt_compiled_cache/AqlmLoraLinear_peft_forward.py          38     27    29%   21-39, 44-67
atomgpt_compiled_cache/AtomGPTAlignPropTrainer.py             183    143    22%   39-49, 174-205, 221-339, 342-345, 363-418, 433-434, 442-448, 451-458, 467-468, 471-472, 485-532, 538-542, 545-546, 565-602, 632-638
atomgpt_compiled_cache/AtomGPTBCOTrainer.py                   625    568     9%   39-49, 264-419, 449-831, 837, 844-866, 873-885, 892-906, 913-939, 943-970, 973-981, 984-996, 1001-1010, 1019-1044, 1057-1090, 1094-1133, 1153-1173, 1178-1222, 1225-1231, 1259-1293, 1301-1385, 1394-1407, 1410-1411, 1414-1416, 1423-1461, 1470-1496, 1514-1553, 1566-1592, 1611-1648, 1712-1824
atomgpt_compiled_cache/AtomGPTCPOTrainer.py                   528    482     9%   39-49, 268-422, 447-689, 701-736, 754-887, 909-949, 967-1000, 1022-1038, 1047-1113, 1122-1167, 1176-1186, 1193-1207, 1216-1242, 1245-1246, 1264-1296, 1309-1318, 1321-1341, 1360-1398, 1450-1557
atomgpt_compiled_cache/AtomGPTDDPOTrainer.py                  254    212    17%   39-49, 199-239, 255-387, 390-407, 426-513, 538-581, 589-595, 598-605, 614-615, 618-619, 632-681, 700-742, 745-769, 775-779, 782-783, 802-841, 867-873
atomgpt_compiled_cache/AtomGPTDPOTrainer.py                   733    679     7%   39-49, 356-525, 554-857, 867-901, 938-959, 970-1006, 1010-1037, 1044-1045, 1061-1098, 1111-1149, 1154-1163, 1167-1175, 1213-1245, 1273-1432, 1439-1608, 1617-1670, 1679-1694, 1701-1741, 1750-1777, 1780-1781, 1799-1834, 1847-1856, 1875-1916, 1973-2089
atomgpt_compiled_cache/AtomGPTGKDTrainer.py                   251    213    15%   39-49, 240-397, 422-490, 495-498, 521-557, 561-592, 597-615, 627-645, 649-676, 695-734, 755-863
atomgpt_compiled_cache/AtomGPTGRPOTrainer.py                  503    452    10%   39-49, 55-92, 109-246, 256-257, 280-343, 350-387, 390-394, 646-802, 824-1011, 1018-1019, 1026, 1033, 1039-1070, 1073, 1076-1238, 1250-1319, 1322-1327, 1330-1342, 1361-1401, 1504-1599
atomgpt_compiled_cache/AtomGPTKTOTrainer.py                   601    553     8%   39-49, 271-426, 454-892, 896-923, 928-937, 946-981, 994-1036, 1040-1115, 1135-1155, 1160-1234, 1261-1306, 1314-1403, 1412-1425, 1428-1429, 1432-1434, 1441-1480, 1489-1516, 1534-1573, 1586-1612, 1631-1668, 1730-1840
atomgpt_compiled_cache/AtomGPTNashMDTrainer.py                288    248    14%   39-49, 217-366, 393-432, 436-440, 443-466, 469-493, 496-511, 514-545, 548-570, 579-590, 606-649, 654-729, 748-787, 846-955
atomgpt_compiled_cache/AtomGPTORPOTrainer.py                  543    496     9%   39-49, 249-399, 424-642, 648-675, 685-720, 738-881, 903-943, 965-974, 996-1012, 1021-1093, 1102-1146, 1155-1168, 1175-1189, 1198-1229, 1232-1233, 1251-1283, 1296-1305, 1308-1328, 1347-1384, 1436-1543
atomgpt_compiled_cache/AtomGPTOnlineDPOTrainer.py             460    415    10%   39-49, 51-55, 261-410, 439-594, 598-602, 607-618, 623-642, 647-691, 694-729, 732-758, 762-780, 785-960, 965-1003, 1015-1045, 1064-1100, 1160-1270
atomgpt_compiled_cache/AtomGPTPPOTrainer.py                   537    500     7%   39-49, 263-432, 456-640, 643, 646, 651-660, 663-675, 678-1013, 1016-1073, 1095-1132, 1152-1259
atomgpt_compiled_cache/AtomGPTPRMTrainer.py                   207    175    15%   39-49, 229-374, 402-498, 551-588, 607-642, 693-800
atomgpt_compiled_cache/AtomGPTRLOOTrainer.py                  426    392     8%   39-49, 260-428, 450-594, 597, 600, 603-924, 927-996, 1018-1058, 1076-1133
atomgpt_compiled_cache/AtomGPTRewardTrainer.py                246    212    14%   39-49, 221-363, 421-541, 550-574, 583-606, 609-611, 621-644, 666-692, 712-819
atomgpt_compiled_cache/AtomGPTSFTTrainer.py                   337    299    11%   39-49, 250-399, 430-517, 521-545, 549-594, 598-603, 607-622, 634-788, 793-799, 802-814, 833-859, 953-1062
atomgpt_compiled_cache/AtomGPTXPOTrainer.py                   324    284    12%   39-49, 216-365, 392-436, 440-444, 447-462, 465-489, 492-507, 510-542, 545-574, 585-614, 632-697, 702-786, 805-842, 901-1010
atomgpt_compiled_cache/AwqLoraLinear_peft_forward.py           38     27    29%   21-39, 43-66
atomgpt_compiled_cache/BatchNorm1d.py                          31     17    45%   30, 43-76
atomgpt_compiled_cache/BatchNorm2d.py                          31     17    45%   30, 43-76
atomgpt_compiled_cache/BatchNorm3d.py                          31     17    45%   30, 43-76
atomgpt_compiled_cache/Conv1d.py                               15      2    87%   30, 43
atomgpt_compiled_cache/Conv2d.py                               15      2    87%   30, 43
atomgpt_compiled_cache/Conv3d.py                               15      2    87%   30, 43
atomgpt_compiled_cache/ConvTranspose1d.py                      21      7    67%   30, 43-61
atomgpt_compiled_cache/ConvTranspose2d.py                      21      7    67%   30, 43-62
atomgpt_compiled_cache/ConvTranspose3d.py                      21      7    67%   30, 43-62
atomgpt_compiled_cache/GPTQLoraLinear_peft_forward.py          40     29    28%   21-39, 44-73
atomgpt_compiled_cache/GroupNorm.py                            16      2    88%   30, 43
atomgpt_compiled_cache/LayerNorm.py                            16      2    88%   30, 43
atomgpt_compiled_cache/Linear4bit_peft_forward.py              50     39    22%   21-39, 44-97
atomgpt_compiled_cache/Linear8bitLt_peft_forward.py            50     39    22%   21-39, 44-90
atomgpt_compiled_cache/Linear_peft_forward.py                  47     36    23%   21-39, 44-89
atomgpt_compiled_cache/LoraParallelLinear_peft_forward.py      46     35    24%   21-39, 44-87
atomgpt_compiled_cache/RMSNorm.py                              16      2    88%   30, 46
atomgpt_compiled_cache/atomgpt_compiled_module_gemma3.py      499    331    34%   30, 41, 46, 56-68, 109-110, 124, 129-133, 142, 145, 148, 155-165, 187, 193-195, 219-223, 232-236, 251-272, 285-340, 383, 438-570, 598, 604, 607, 610, 628, 644-685, 690-705, 709-722, 725, 804-959, 974-986, 989, 992, 995, 998, 1001, 1004, 1015-1073, 1085-1087, 1107, 1125-1150, 1153
atomgpt_compiled_cache/atomgpt_compiled_module_mllama.py      528    308    42%   30, 41, 46, 56-68, 112-127, 135-152, 156-163, 178, 184-196, 219, 224-227, 238, 248-277, 298, 309-333, 343, 348-352, 364, 367, 382-428, 466, 475-479, 494-548, 568, 574-576, 600-604, 619-659, 690, 705-752, 767, 772-773, 788, 795-805, 822, 882-1017, 1048, 1051, 1054, 1057, 1060, 1082
atomgpt_compiled_cache/atomgpt_compiled_module_siglip.py      243    161    34%   30, 41, 46, 56-68, 111-141, 166-168, 173-194, 199, 204, 209-218, 222-239, 251-277, 280, 290-308, 312-319, 329, 343-353, 365-402, 408-425, 433, 438-441, 445-449, 452, 457-466, 472-477, 480
-----------------------------------------------------------------------------------------
TOTAL                                                       22180  16472    26%

